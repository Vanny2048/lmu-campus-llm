#!/usr/bin/env python3
"""
LMU Buddy Fine-tuning Setup Script
Complete setup and fine-tuning process for LMU Buddy with Ollama
"""

import os
import sys
import subprocess
import platform
import requests
import time
from pathlib import Path

def print_banner():
    """Print the setup banner"""
    print("ğŸ¦" * 50)
    print("ğŸ¦ LMU Buddy Fine-tuning Setup")
    print("ğŸ¦" * 50)
    print()

def check_python_version():
    """Check if Python version is compatible"""
    print("ğŸ Checking Python version...")
    version = sys.version_info
    if version.major < 3 or (version.major == 3 and version.minor < 8):
        print("âŒ Python 3.8 or higher is required!")
        print(f"Current version: {version.major}.{version.minor}.{version.micro}")
        return False
    print(f"âœ… Python {version.major}.{version.minor}.{version.micro} is compatible")
    return True

def install_ollama():
    """Install Ollama based on the operating system"""
    print("\nğŸ“¦ Installing Ollama...")
    
    system = platform.system().lower()
    
    if system == "linux":
        print("ğŸ§ Installing Ollama on Linux...")
        try:
            # Download and install Ollama
            install_script = """
            curl -fsSL https://ollama.ai/install.sh | sh
            """
            result = subprocess.run(install_script, shell=True, capture_output=True, text=True)
            if result.returncode == 0:
                print("âœ… Ollama installed successfully!")
                return True
            else:
                print(f"âŒ Failed to install Ollama: {result.stderr}")
                return False
        except Exception as e:
            print(f"âŒ Error installing Ollama: {e}")
            return False
    
    elif system == "darwin":  # macOS
        print("ğŸ Installing Ollama on macOS...")
        try:
            # Use Homebrew if available
            result = subprocess.run(['brew', '--version'], capture_output=True, text=True)
            if result.returncode == 0:
                print("Using Homebrew to install Ollama...")
                result = subprocess.run(['brew', 'install', 'ollama'], capture_output=True, text=True)
                if result.returncode == 0:
                    print("âœ… Ollama installed successfully!")
                    return True
                else:
                    print(f"âŒ Failed to install Ollama via Homebrew: {result.stderr}")
            else:
                print("Homebrew not found. Please install Ollama manually from https://ollama.ai/")
                return False
        except Exception as e:
            print(f"âŒ Error installing Ollama: {e}")
            return False
    
    elif system == "windows":
        print("ğŸªŸ Installing Ollama on Windows...")
        print("Please download and install Ollama from https://ollama.ai/")
        print("After installation, restart your terminal and run this script again.")
        return False
    
    else:
        print(f"âŒ Unsupported operating system: {system}")
        print("Please install Ollama manually from https://ollama.ai/")
        return False

def check_ollama_installation():
    """Check if Ollama is properly installed and running"""
    print("\nğŸ” Checking Ollama installation...")
    
    try:
        # Check if ollama command is available
        result = subprocess.run(['ollama', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… Ollama is installed: {result.stdout.strip()}")
            
            # Check if Ollama service is running
            try:
                response = requests.get('http://localhost:11434/api/tags', timeout=5)
                if response.status_code == 200:
                    print("âœ… Ollama service is running")
                    return True
                else:
                    print("âŒ Ollama service is not responding")
                    return False
            except requests.exceptions.RequestException:
                print("âŒ Ollama service is not running")
                print("Starting Ollama service...")
                try:
                    subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                    time.sleep(3)  # Wait for service to start
                    
                    # Check again
                    response = requests.get('http://localhost:11434/api/tags', timeout=5)
                    if response.status_code == 200:
                        print("âœ… Ollama service started successfully")
                        return True
                    else:
                        print("âŒ Failed to start Ollama service")
                        return False
                except Exception as e:
                    print(f"âŒ Error starting Ollama service: {e}")
                    return False
        else:
            print("âŒ Ollama is not properly installed")
            return False
    except FileNotFoundError:
        print("âŒ Ollama is not installed")
        return False

def install_python_dependencies():
    """Install required Python dependencies"""
    print("\nğŸ“š Installing Python dependencies...")
    
    try:
        result = subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… Python dependencies installed successfully!")
            return True
        else:
            print(f"âŒ Failed to install dependencies: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ Error installing dependencies: {e}")
        return False

def run_fine_tuning():
    """Run the fine-tuning process"""
    print("\nğŸš€ Starting fine-tuning process...")
    
    try:
        result = subprocess.run([sys.executable, 'fine_tune_lmu_buddy.py'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… Fine-tuning completed successfully!")
            return True
        else:
            print(f"âŒ Fine-tuning failed: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ Error running fine-tuning: {e}")
        return False

def test_integration():
    """Test the integration with the Streamlit app"""
    print("\nğŸ§ª Testing integration...")
    
    try:
        result = subprocess.run([sys.executable, 'lmu_buddy_ollama_client.py'], 
                              capture_output=True, text=True, timeout=60)
        if result.returncode == 0:
            print("âœ… Integration test completed!")
            return True
        else:
            print(f"âš ï¸ Integration test had issues: {result.stderr}")
            return True  # Don't fail the setup for test issues
    except subprocess.TimeoutExpired:
        print("âš ï¸ Integration test timed out, but this is normal")
        return True
    except Exception as e:
        print(f"âš ï¸ Error during integration test: {e}")
        return True

def print_next_steps():
    """Print next steps for the user"""
    print("\n" + "ğŸ‰" * 20)
    print("ğŸ‰ SETUP COMPLETED SUCCESSFULLY! ğŸ‰")
    print("ğŸ‰" * 20)
    print()
    print("ğŸ“‹ Next Steps:")
    print("1. ğŸš€ Start your Streamlit app:")
    print("   streamlit run app.py")
    print()
    print("2. ğŸ§ª Test the fine-tuned model:")
    print("   python lmu_buddy_ollama_client.py")
    print()
    print("3. ğŸ¦ Use the model directly:")
    print("   ollama run lmu-buddy 'Where should I eat on campus?'")
    print()
    print("4. ğŸ“š Check the generated files:")
    print("   - Modelfile (Ollama model configuration)")
    print("   - lmu_buddy_training_data.json (Training data)")
    print()
    print("ğŸ”§ Troubleshooting:")
    print("- If Ollama service stops, run: ollama serve")
    print("- To see available models: ollama list")
    print("- To remove the model: ollama rm lmu-buddy")
    print("- To recreate the model: python fine_tune_lmu_buddy.py")
    print()

def main():
    """Main setup function"""
    print_banner()
    
    # Step 1: Check Python version
    if not check_python_version():
        return False
    
    # Step 2: Install Python dependencies
    if not install_python_dependencies():
        return False
    
    # Step 3: Check Ollama installation
    if not check_ollama_installation():
        print("\nğŸ“¦ Ollama not found. Installing...")
        if not install_ollama():
            print("\nâŒ Failed to install Ollama automatically.")
            print("Please install Ollama manually from https://ollama.ai/")
            print("Then run this script again.")
            return False
        
        # Check again after installation
        if not check_ollama_installation():
            print("\nâŒ Ollama installation verification failed.")
            return False
    
    # Step 4: Run fine-tuning
    if not run_fine_tuning():
        print("\nâŒ Fine-tuning failed. Please check the logs above.")
        return False
    
    # Step 5: Test integration
    test_integration()
    
    # Step 6: Print next steps
    print_next_steps()
    
    return True

if __name__ == "__main__":
    success = main()
    if not success:
        print("\nâŒ Setup failed. Please check the errors above and try again.")
        sys.exit(1)